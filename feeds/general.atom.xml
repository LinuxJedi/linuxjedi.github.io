<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>LinuxJedi's /dev/null</title><link href="http://linuxjedi.co.uk/" rel="alternate"></link><link href="http://linuxjedi.co.uk/feeds/general.atom.xml" rel="self"></link><id>http://linuxjedi.co.uk/</id><updated>2015-01-20T09:16:00+00:00</updated><entry><title>The Pointer Corruption Bug</title><link href="http://linuxjedi.co.uk/posts/2015/Jan/20/the-pointer-corruption-bug/" rel="alternate"></link><updated>2015-01-20T09:16:00+00:00</updated><author><name></name></author><id>tag:linuxjedi.co.uk,2015-01-20:posts/2015/Jan/20/the-pointer-corruption-bug/</id><summary type="html">&lt;p&gt;Or an alternative name for this post...&lt;/p&gt;
&lt;div class="section" id="why-api-docs-should-have-examples"&gt;
&lt;h2&gt;Why API Docs Should Have Examples&lt;/h2&gt;
&lt;p&gt;As part of my continuation of libAttachSQL for HP's Advanced Technology Group I have recently been focusing on a Python based wrapper called pyAttachSQL.  This is currently at an alpha level of release with no package builds yet.&lt;/p&gt;
&lt;p&gt;Today I want to talk about one (silly on my part) very frustrating bug I found whilst working on pyAttachSQL and why this means API docs should have examples for every call.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="the-crash"&gt;
&lt;h2&gt;The Crash&lt;/h2&gt;
&lt;p&gt;Whilst writing the group connection functions I was using a &lt;a class="reference external" href="https://docs.python.org/2/c-api/arg.html#c.Py_BuildValue"&gt;Py_BuildValue&lt;/a&gt; call to generate parameters to use in a callback &lt;a class="reference external" href="https://docs.python.org/2/c-api/object.html#c.PyObject_CallObject"&gt;PyObject_CallObject&lt;/a&gt;.  So the code looked a little like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;cbargs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Py_BuildValue&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;iOOO&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;events&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;pycon&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;pycon&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;query&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;self&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;cb_args&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;...&lt;/span&gt;
&lt;span class="n"&gt;PyObject_CallObject&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;self&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;cb_func&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cbargs&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;Py_DECREF&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cbargs&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Those who are Python API veterans will be able to see straight away where I went wrong but I am quite new to the API.  The code was segfaulting on &lt;tt class="docutils literal"&gt;PyObject_CallObject&lt;/tt&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="my-big-dumb-mistake"&gt;
&lt;h2&gt;My Big Dumb Mistake&lt;/h2&gt;
&lt;img alt="" src="/images/droids.jpg" /&gt;
&lt;p&gt;Whilst debugging this I found the problem was in &lt;tt class="docutils literal"&gt;cbargs&lt;/tt&gt;, for some reason the pointers to &lt;tt class="docutils literal"&gt;pycon&lt;/tt&gt; and alike were slightly different to when they were set.  After some time going over it again and again in GDB and watching the pointers get incremented it suddenly hit me.  The incrementation was happening during reference increment functions inside &lt;tt class="docutils literal"&gt;Py_BuildValue&lt;/tt&gt;.  Which makes sense because the one first items in a &lt;tt class="docutils literal"&gt;PyObject&lt;/tt&gt; structure is the reference count.  I was supposed to pass pointers, not pointers to pointers.  The &lt;tt class="docutils literal"&gt;Py_BuildValue&lt;/tt&gt; function has no type checking so was taking whatever you passed to it as a pointer to a structure.&lt;/p&gt;
&lt;p&gt;So the question many of you would be asking is: why did you pass pointers to pointers?  That is easy to answer...  Earlier in the code I have been using the &lt;a class="reference external" href="https://docs.python.org/2/c-api/arg.html#c.PyArg_ParseTuple"&gt;PyArg_ParseTuple&lt;/a&gt; and similar functions which are on the same documentation page, using a similar API and I assumed the API was consistent with no examples to show me otherwise.  The fix was to simply remove the &lt;tt class="docutils literal"&gt;&amp;amp;&lt;/tt&gt; symbols from the above code.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="lessons-learnt"&gt;
&lt;h2&gt;Lessons Learnt&lt;/h2&gt;
&lt;p&gt;I guess there is two lessons I have learnt from this:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Don't assume that an API is consistent&lt;/li&gt;
&lt;li&gt;Add examples for every API call in the documentation&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I'll shortly be opening a ticket for libAttachSQL and pyAttachSQL to implement the second item.&lt;/p&gt;
&lt;/div&gt;
</summary><category term="HP"></category><category term="Advanced Technology Group"></category><category term="C"></category><category term="Python"></category><category term="API"></category><category term="Documentation"></category><category term="libAttachSQL"></category></entry><entry><title>YubiKey for OS Logins</title><link href="http://linuxjedi.co.uk/posts/2015/Jan/19/yubikey-for-os-logins/" rel="alternate"></link><updated>2015-01-19T16:14:00+00:00</updated><author><name></name></author><id>tag:linuxjedi.co.uk,2015-01-19:posts/2015/Jan/19/yubikey-for-os-logins/</id><summary type="html">&lt;p&gt;I have mentioned a few times in this blog that HP takes security very seriously and HP's Advanced Technology Group is always looking into new ways of making things secure.  Recently the team all got a &lt;a class="reference external" href="https://www.yubico.com/products/yubikey-hardware/yubikey-neo/"&gt;YubiKey Neo&lt;/a&gt; to use.  The initial idea was we would be trying the FIDO U2F with Google accounts but several of us went much further.&lt;/p&gt;
&lt;p&gt;Yazz Atlas from our team has been working on getting his SSH key into the NEO with some success.  I initially got my GPG key to work with the smart card feature in the NEO and have since been tinkering with a couple of other things.&lt;/p&gt;
&lt;p&gt;I happened to find an original YubiKey in a drawer which was used for OTP two-factor authentication to a server I no longer have access to.  I wanted to use this as a way of two-factor authentication for my computers.  Unfortunately there is no good way of doing this on the Mac at the moment so I came up with a different way of doing a less secure two-factor authentication with it (but more secure than a fixed password).&lt;/p&gt;
&lt;p&gt;The original YubiKey's have two &amp;quot;slots&amp;quot; in them.  Each slot can store either an OTP two-factor authentication identity or a static password.  You can tap a YubiKey to get the first slot and hold for around 3 seconds for the second slot.  The way I'm using this is to have the slots store static passwords, I then have a hand typed part of my password and a second static part stored on the YubiKey.  This means that if the YubiKey is stolen/used it is useless without my hand typed-part.  I have a backup of the YubiKey's static password in my &lt;a class="reference external" href="https://lastpass.com/"&gt;LastPass&lt;/a&gt; account (which incidentally uses two-factor authentication).&lt;/p&gt;
&lt;p&gt;There was a minor snag in this to begin with, my Macs are encrypted with FileVault which has a known login problem.  If you type a password too quickly it actually drops some of characters that you have typed.  The YubiKey is a virtual keyboard and although it deliberately doesn't type too quickly, it is too fast for FileVault.  If your YubiKey is a version 2.3 or higher this is easy to fix.  In the &lt;a class="reference external" href="https://www.yubico.com/products/services-software/personalization-tools/"&gt;YubiKey Personalization Tool&lt;/a&gt; you can go to settings and change the output frequency, this setting change can then be used to update a slot.  But if like me your original YubiKey is an older version you cannot do this.  There is a way around this by generating a new key, but it requires the command line (the GUI doesn't have the options to change the delay whilst generating a new key).&lt;/p&gt;
&lt;p&gt;First of all you need the command line YubiKey Personalization Tool.  There are &lt;a class="reference external" href="https://yubico.github.io/yubikey-personalization/releases.html"&gt;Linux, Mac and Windows versions available&lt;/a&gt; and some Linux distros have it in their repository.  Using this tool you can generate a new random static password with a typing delay as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;ykpersonalize -2 -opacing-20ms -ostrong-pw2 -ostrong-pw1 -ostatic-token
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can change the &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;-2&lt;/span&gt;&lt;/tt&gt; to &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;-1&lt;/span&gt;&lt;/tt&gt; if you wish to program slot 1 instead.  The typing delay is added using the &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;pacing-20ms&lt;/span&gt;&lt;/tt&gt; option.  Unfortunately this flag doesn't quite match the GUI, if you want to match the GUI options here is what you need to use:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;20ms Delay - &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;pacing-10ms&lt;/span&gt;&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;40ms Delay - &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;pacing-20ms&lt;/span&gt;&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;60ms Delay - &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;pacing-20ms&lt;/span&gt;&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;pacing-10ms&lt;/span&gt;&lt;/tt&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For FileVault it is recommended you using the 40ms delay as a minimum.  The 20ms delay works most of the time but can still fail.&lt;/p&gt;
&lt;p&gt;So, now to log into my machines I type in the part of the password I have remembered and then press the YubiKey to fill in the rest of the password.&lt;/p&gt;
</summary><category term="YubiKey"></category><category term="Security"></category><category term="HP"></category><category term="Advanced Technology Group"></category></entry><entry><title>USB Flash Drives - Trimming the FAT</title><link href="http://linuxjedi.co.uk/posts/2015/Jan/05/usb-flash-drives-trimming-the-fat/" rel="alternate"></link><updated>2015-01-05T22:34:00+00:00</updated><author><name></name></author><id>tag:linuxjedi.co.uk,2015-01-05:posts/2015/Jan/05/usb-flash-drives-trimming-the-fat/</id><summary type="html">&lt;p&gt;As with most of you who read this blog I carry USB flash drives around with me all the time.  Right now I have 3 Kingston DTSE9 sticks on my keyring of various sizes each with a different purpose.  Whilst these drives are nowhere near the fastest out there they are the only ones I have had so far that don't snap off keyrings.&lt;/p&gt;
&lt;img alt="" src="/images/king16GB_DTSE9_2.jpg" /&gt;
&lt;p&gt;For this blog post I'll be talking about data where security is not a priority.  My encrypted flash drives are currently using &lt;a class="reference external" href="https://veracrypt.codeplex.com/"&gt;VeraCrypt&lt;/a&gt; but that is beyond the scope of this blog post.&lt;/p&gt;
&lt;div class="section" id="fat32-woes"&gt;
&lt;h2&gt;FAT32 woes&lt;/h2&gt;
&lt;p&gt;The largest one I have is 64GB and due to some of the work I do for HP's Advanced Technology Group this often needs to have large files on it.  Traditionally FAT32 has been used as a file system for memory cards and flash drives, one of the biggest reasons for this is that it is compatible with pretty much every computer operating system out there.  But FAT32 has many flaws:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;it has a single file limit of 4GB.  That may sound huge but this rules out DVD images and large databases.&lt;/li&gt;
&lt;li&gt;it does not support POSIX based permissions which anyone who uses Linux is used to.&lt;/li&gt;
&lt;li&gt;it doesn't support journalling so with a removable drive data corruption is very common.&lt;/li&gt;
&lt;li&gt;as a minor issue it is also designed for spinning disks with many more write cycles than flash.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What I needed was something that fixes as many of those problems as possible but is also compatible with Linux, Mac OS X and Windows.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="alternatives"&gt;
&lt;h2&gt;Alternatives&lt;/h2&gt;
&lt;p&gt;I looked into several alternatives to FAT32 and summarised my findings below.  I'm primarily looking for out-of-box support, I know there are paid third-party add-ons to operating systems to add support.&lt;/p&gt;
&lt;div class="section" id="exfat"&gt;
&lt;h3&gt;exFAT&lt;/h3&gt;
&lt;p&gt;A company looked into all the problems with FAT and created a filesystem designed for use with flash drives, they called this &lt;em&gt;exFAT&lt;/em&gt;.  Unfortunately that company is Microsoft and what they created is not an open standard and is full of patents.&lt;/p&gt;
&lt;p&gt;This means that only people who have paid licenses can use exFAT.  This includes Mac OS X and digital camera manufacturers but unfortunately means Linux support is very limited.&lt;/p&gt;
&lt;p&gt;exFAT is therefore thrown out.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="hfs"&gt;
&lt;h3&gt;HFS+&lt;/h3&gt;
&lt;p&gt;HFS+ is the primary file system used by Mac OS X.  There is good support for this in Macs (obviously) and Linux, but no support in Windows.&lt;/p&gt;
&lt;p&gt;Unfortunately that means HFS+ is out.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="ntfs"&gt;
&lt;h3&gt;NTFS&lt;/h3&gt;
&lt;p&gt;NTFS is Microsoft's primary file system in NT based operating systems (for most people this means Windows XP onwards).  Like HFS+ it isn't a bad file system for flash drives and in recent Linux distributions has very good support.  Unfortunately in Mac OS X it can only be used in read-only mode.&lt;/p&gt;
&lt;p&gt;Another Microsoft FS thrown out.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="udf"&gt;
&lt;h3&gt;UDF&lt;/h3&gt;
&lt;p&gt;Yes, you read that correctly, UDF.  It is a filesystem which was originally designed for use with optical media.  But, it has since been adapted for use with hard drives and flash drives!&lt;/p&gt;
&lt;p&gt;The maximum file size is 16EB (actually bigger than the maximum volume size).  It supports POSIX file system permissions.  But most importantly, it works with Linux, Mac OS X and Windows (Vista onwards) out of the box!&lt;/p&gt;
&lt;p&gt;In addition the UDF format was designed for packet writing so it works by appending on the end of data on the file system and expiring the old data.  In theory this could lead to less wear of the drive.  Flash drives typically use dynamic wear leveling which is similar to the static wear leveling used in SSDs but less complex.  The algorithm used may mean that the packet writing has no real advantage on the wear of the drive.  I don't have enough data to say for certain.&lt;/p&gt;
&lt;p&gt;The file system itself works like a journal.  It appends new data to the end of the log with a new version of the file table.  So, if a write was not completed successfully it will use the previous version of the log.  This also means recovery of deleted files is possible by traversing previous versions of the data log.&lt;/p&gt;
&lt;p&gt;For me this ticks all the boxes so I am using it with a 64GB UDF formatted flash.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="making-a-udf-flash-drive"&gt;
&lt;h2&gt;Making a UDF flash drive&lt;/h2&gt;
&lt;div class="section" id="mac-os-x"&gt;
&lt;h3&gt;Mac OS X&lt;/h3&gt;
&lt;p&gt;Unfortunately Disk Utility doesn't let you format a flash drive as UDF but you can use the command line to do it.&lt;/p&gt;
&lt;p&gt;First of all you need to figure out the drive path for your flash drive.  It will be in the format &lt;tt class="docutils literal"&gt;/dev/disk{drive_no}&lt;/tt&gt; where drive_no is the drive number, if it is followed by the letter &lt;em&gt;s&lt;/em&gt; and another number then that is a partition and not what we need at this stage:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;diskutil list
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now you need to find out the block size (it is typically 512).  Make a note of this number because you will need it later:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;diskutil info /dev/disk&lt;span class="o"&gt;{&lt;/span&gt;drive_no&lt;span class="o"&gt;}&lt;/span&gt; | grep &lt;span class="s2"&gt;&amp;quot;Block Size&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The drive can't be changed until we unmount the partitions so run this for every partition that is currently in-use for your drive:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;diskutil unmount /dev/disk&lt;span class="o"&gt;{&lt;/span&gt;drive_no&lt;span class="o"&gt;}&lt;/span&gt;s&lt;span class="o"&gt;{&lt;/span&gt;partition_no&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Due to the nature of the UDF format it is possible that the operating system would still detect the drive as FAT32 afterwards so we need to blank the drive with zeros.  This could take some time:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;diskutil secureErase 0 /dev/disk&lt;span class="o"&gt;{&lt;/span&gt;drive_no&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now the drive can be formatted, replace &lt;em&gt;block_size&lt;/em&gt; with the number you wrote down above:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;sudo newfs_udf -b &lt;span class="o"&gt;{&lt;/span&gt;block_size&lt;span class="o"&gt;}&lt;/span&gt; /dev/disk&lt;span class="o"&gt;{&lt;/span&gt;drive_no&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally the drive can be mounted again for use as normal:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;diskutil mount /dev/disk&lt;span class="o"&gt;{&lt;/span&gt;drive_no&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="linux"&gt;
&lt;h3&gt;Linux&lt;/h3&gt;
&lt;p&gt;In Linux things get a little easier.  First of all unmount the partitions on the drive and then we need the block size, write this one down:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;sudo blockdev --getbsz /dev/sd&lt;span class="o"&gt;{&lt;/span&gt;drive_letter&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We then need to zero out the drive so that it isn't incorrectly detected:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;sudo dd &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/dev/zero &lt;span class="nv"&gt;of&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/dev/sd&lt;span class="o"&gt;{&lt;/span&gt;drive_letter&lt;span class="o"&gt;}&lt;/span&gt; &lt;span class="nv"&gt;bs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;1M &lt;span class="nv"&gt;count&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;1
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then we need to make the UDF format, replacing &lt;em&gt;block_size&lt;/em&gt; with the number noted above:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;sudo mkudffs -b &lt;span class="o"&gt;{&lt;/span&gt;block_size&lt;span class="o"&gt;}&lt;/span&gt; --media-type&lt;span class="o"&gt;=&lt;/span&gt;hd /dev/sd&lt;span class="o"&gt;{&lt;/span&gt;drive_letter&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</summary><category term="USB"></category><category term="Flash"></category><category term="Filesystems"></category><category term="HP"></category><category term="Advanced Technology Group"></category></entry><entry><title>Family Travel Technology</title><link href="http://linuxjedi.co.uk/posts/2014/Dec/28/family-travel-technology/" rel="alternate"></link><updated>2014-12-28T16:18:00+00:00</updated><author><name></name></author><id>tag:linuxjedi.co.uk,2014-12-28:posts/2014/Dec/28/family-travel-technology/</id><summary type="html">&lt;p&gt;My family and I spent a few days before Christmas visiting family away from home.  We booked two interconnecting hotel rooms so our children could have their own room and we could sleep with a little bit of peace.  As with many trips there is often a period between dinner and sleep where you are stuck in a hotel room with nothing to do so this time I devised a plan for entertainment.&lt;/p&gt;
&lt;p&gt;First of all, we all have internet connected devices, between phones, gaming devices, my laptop, etc... we actually had 9 devices with us (some I will talk about later in this post).  As with many hotel WiFi plans there is a cap on the number of devices you can have assigned to your room.  The WiFi itself was quite speedy for a hotel and was fast enough to share across several devices.  To get around this limit and also to create our own personal network I used a &lt;a class="reference external" href="http://www.netgear.co.uk/home/products/networking/wifi-routers/PR2000.aspx"&gt;Netgear PR2000 Travel Router&lt;/a&gt;.&lt;/p&gt;
&lt;img alt="" src="/images/netgear.jpg" /&gt;
&lt;p&gt;The Netgear router connects to a public network via. a network cable or WiFi and creates its own WiFi/wired network for you to use.  This means you use any one of your devices to log into the hotel WiFi and to the hotel it looks like just the router is connected.  This is a fantastic device and I benchmarked it before I went on vacation, I was easily pushing 20mbit over the internet in both directions with it in less than ideal conditions so it is was perfect for travelling with.  I absolutely love this device and I think the only flaw I have found with it is that it gets into a reboot loop after you first configure it and have to power cycle it to make it work.&lt;/p&gt;
&lt;p&gt;The only thing I would like to see improved with this device is the inclusion of a US power connector.  It can be powered via. USB or by clipping on an included EU or UK power plug.  If you power it using a wall plug connection you can use the USB port on the device to share a USB stick or drive across your private network.  That said I've tested and a C7 (figure of 8) power cable will be compatible if not elegant to look at, much like using a C7 in an Apple Mac power adaptor.&lt;/p&gt;
&lt;p&gt;As part of the entertainment we wanted a movie night.  The children had a selection of films they wanted to watch and I had already transcoded them from their DVDs onto my laptop.  My wife and I are currently watching box sets of the TV series of 24 and we wanted to watch this.  So, in the children's room I hooked my Apple TV into their TV and in our room I used the HDMI on my Macbook Pro (2014 13&amp;quot; retina model) in our room.  The Macbook Pro does not have an included DVD drive, luckily earlier this year I bought a USB &lt;a class="reference external" href="https://www.samsung.com/uk/consumer/memory-cards-hdd-odd/odd/odd/SE-S084D/TSBS"&gt;Samsung S084D DVD drive&lt;/a&gt; second hand for Â£4.&lt;/p&gt;
&lt;p&gt;To stream the video to the Apple TV in the children's room I used an application called &lt;a class="reference external" href="http://beamer-app.com/"&gt;Beamer&lt;/a&gt;.  This converted the video on-the-fly to a format the Apple TV could use and streamed it.  It has worked great with every file format I have thrown at it and automatically find the Apple TV with no problems.  With the time slider on it I could also see how long was left on the film before they had finished with it.  Whilst in the parents room we were using Apple's built-in DVD player.&lt;/p&gt;
&lt;p&gt;The whole setup worked perfectly, throughout the stay the children watched two films on the Apple TV using Beamer and we got half way through a series of 24.  Being my geeky self I'm impressed at how well the setup glued together mostly with parts I already had at home.  The whole lot fitted easily in my backpack and I had lots of space to spare for other things.&lt;/p&gt;
</summary><category term="Apple"></category><category term="Netgear"></category><category term="Beamer"></category></entry><entry><title>Autotools and Mac Universal binaries</title><link href="http://linuxjedi.co.uk/posts/2014/Nov/25/autotools-and-mac-universal-binaries/" rel="alternate"></link><updated>2014-11-25T16:38:00+00:00</updated><author><name></name></author><id>tag:linuxjedi.co.uk,2014-11-25:posts/2014/Nov/25/autotools-and-mac-universal-binaries/</id><summary type="html">&lt;p&gt;Recently I have been working on a Python based wrapper for &lt;a class="reference external" href="http://libattachsql.org/"&gt;libAttachSQL&lt;/a&gt; and found that when testing on a Mac I was having trouble compiling the wrapper.  It turns out that Python included in Mac operating systems uses a universal binary (also called fat binary) format and since libAttachSQL is not compiled that way it would not link correctly.&lt;/p&gt;
&lt;p&gt;For those who have never come across this, Universal binaries were originally intended to contain executables for multiple platforms (such as PPC and i386) to ease hardware transition.  The OS will only load the compatible part into memory and use that.  Python as well as several other current Mac binaries are compiled to have i386 and x86_64 binaries in one package.&lt;/p&gt;
&lt;p&gt;Compiling a Universal binary is actually relatively easy but I didn't want to put the hard work on the use who is compiling the library and I wanted something I could use in other projects in the future.  So I have created an m4 script which can be used with Autotools to build Universal binaries.  This can be found in my &lt;a class="reference external" href="https://github.com/LinuxJedi/m4scripts"&gt;m4 scripts GitHub repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The script in question is called &lt;tt class="docutils literal"&gt;ax_mac_universal.m4&lt;/tt&gt; and when the &lt;tt class="docutils literal"&gt;AX_UNIVERSAL_BINARY&lt;/tt&gt; macro is used it will automatically detect if the environment supports universal binaries and add the necessary compiler flags to build them.  It also adds &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;--enable-universal-binary&lt;/span&gt;&lt;/tt&gt; to configure so that you can force this feature on/off at will.&lt;/p&gt;
&lt;p&gt;This script will be included as part of the upcoming libAttachSQL 1.0.2 release.&lt;/p&gt;
</summary><category term="HP"></category><category term="Advanced Technology Group"></category><category term="libAttachSQL"></category><category term="Autotools"></category></entry><entry><title>Why JSON is bad for applications</title><link href="http://linuxjedi.co.uk/posts/2014/Oct/31/why-json-is-bad-for-applications/" rel="alternate"></link><updated>2014-10-31T20:39:00+00:00</updated><author><name></name></author><id>tag:linuxjedi.co.uk,2014-10-31:posts/2014/Oct/31/why-json-is-bad-for-applications/</id><summary type="html">&lt;p&gt;Today I read an article about how company X has improved things by amongst other things ditching JSON after 2 years of using it.  Before I start on this subject I should say that JSON does have its place.  If you have a web application where a browser is talking to a web server and in particular uses JavaScript then JSON is a good fit.&lt;/p&gt;
&lt;p&gt;I've discussed this issue several times before with &lt;a class="reference external" href="http://krow.net/"&gt;Brian Aker&lt;/a&gt; who works with me at HP's Advanced Technology Group and in the past I have been hit with the issues I'm going to talk about here.&lt;/p&gt;
&lt;p&gt;JSON is human readable and easy to parse, that cannot be denied and for prototyping is good in a pinch.  The first problem comes when you need to validate data.  I've been stung many times by one end trying to read/write the JSON in a slightly different format to the other end, the end result is always not pretty.  This is one advantage that XML and SOAP has going for it over JSON since validation is easier.  I'm personally not a fan of XML but there are many who are.&lt;/p&gt;
&lt;p&gt;There are additional problems when you start using mobile platforms.  Mobile networks are unreliable, you may have a good 3G signal but it is possible to only get dial-up speed through it due to all the other users.  JSON is verbose, XML more so which requires more data transfer.  Whilst this can be resolved with protocol compression it will require additional decoding on the client side to do this.  In addition data conversion will be needed in many cases for numeric fields.&lt;/p&gt;
&lt;p&gt;The biggest problem with JSON is versioning.  As you add more features to your application there will likely come a time where you need to change the data structure for your messages.  Often you can't guarantee that your client is using the same version of the software as your server so backwards and forwards compatibility problems can arise.  Resolving these often makes the JSON messages very complex to create and decode.  This is not as much of a problem for web applications because the browser usually grabs an update version of the JavaScript on execution.  So changing the data format at any time is easy as long as both ends agree on the format.&lt;/p&gt;
&lt;div class="section" id="the-solution"&gt;
&lt;h2&gt;The solution&lt;/h2&gt;
&lt;p&gt;For many applications the data you are sending is directly from a database or at least data that has been modified since being read from a database.  So you will likely want the data model for your messages to match this as much as possible.  This is where &lt;a class="reference external" href="https://developers.google.com/protocol-buffers/"&gt;Google's Protocol Buffers&lt;/a&gt; fit nicely.&lt;/p&gt;
&lt;p&gt;Protocol Buffers allow you to specify a schema for the data in a human readable format, it actually looks a little like a database schema.  They will automatically validate the data for you and have versioning built-in.  This means you can make your code easily backwards and forwards compatible.&lt;/p&gt;
&lt;p&gt;There is a positive and negative side to the data transfer of Protocol Buffers.  It is a binary protocol.  This means it takes up minimal bandwidth on the wire but also means that it is not human readable and difficult to figure out which data is for which field (although should not be used for security through obscurity).  The same could be said if you were given InnoDB table data without the schemas.  It also means it may be possible to compress the data further with something like LZO or DEFLATE.&lt;/p&gt;
&lt;p&gt;I recommend application developers consider Protocol Buffers instead of JSON when they are next developing a server/client application.&lt;/p&gt;
&lt;div class="note"&gt;
&lt;p class="first admonition-title"&gt;Note&lt;/p&gt;
&lt;p class="last"&gt;I updated this article to explain the binary protocol a little better.  Thanks to Antony Curtis for pointing it out.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</summary><category term="HP"></category><category term="Advanced Technology Group"></category></entry><entry><title>Blogging Platforms</title><link href="http://linuxjedi.co.uk/posts/2014/Oct/04/blogging-platforms/" rel="alternate"></link><updated>2014-10-04T22:16:00+01:00</updated><author><name></name></author><id>tag:linuxjedi.co.uk,2014-10-04:posts/2014/Oct/04/blogging-platforms/</id><summary type="html">&lt;p&gt;A couple of weeks ago I ditched Blogger as my main blogging platform.  The main reason for this was the editing tools were breaking posts containing code.  Whilst it is a great platform for basic blogging, it is not suitable for developers blogs.&lt;/p&gt;
&lt;p&gt;So, I was on the hunt for blogging platforms that would make it easy for me to write posts that contain technical content and is not expensive to run.  I also don't want to be maintaining my own web server, I may be capable of doing this but I don't want the time overhead.&lt;/p&gt;
&lt;p&gt;I tried several things out that met some of my requirements but many didn't fit all.  Wordpress was probably the closest, but I had trouble bending the free templates to my will.&lt;/p&gt;
&lt;p&gt;With many on my team at HP's Advanced Technology Group using &lt;a class="reference external" href="https://pages.github.com/"&gt;GitHub Pages&lt;/a&gt; for blog posts I thought I would give it a try.  Most of the team are trying out Jekyll which looks really good, but isn't for me.  I prefer &lt;a class="reference external" href="http://docutils.sourceforge.net/rst.html"&gt;reStructuredText&lt;/a&gt; to Markdown and use it every day for the &lt;a class="reference external" href="http://docs.libattachsql.org"&gt;libAttachSQL documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;On my journey I came across &lt;a class="reference external" href="http://tinkerer.me/"&gt;Tinkerer&lt;/a&gt; which is a layer on top of &lt;a class="reference external" href="http://sphinx-doc.org/"&gt;Python Sphinx&lt;/a&gt; to generate a blog site from RST files.  This was great for me because Sphinx is the renderer used for libAttachSQL's docs both in the build system and &lt;a class="reference external" href="https://readthedocs.org/"&gt;Read The Docs&lt;/a&gt;.  I created a new blog on this hosted on GitHub Pages and &lt;a class="reference external" href="https://disqus.com/"&gt;Disqus&lt;/a&gt; for comments.&lt;/p&gt;
&lt;p&gt;I had several minor problems with Tinkerer, many of which I worked around, but the main flaw was no timestamp support for blog posts.  All blog posts would have a date but not a time, so in the RSS feeds it would be as if they were posted at midnight.  If you are posting at 22:00 it means in feed aggregators your post would end up below many others posted that day and multiple posts in a day could be in any order.&lt;/p&gt;
&lt;p&gt;Today I bumped into a blogging platform called &lt;a class="reference external" href="http://blog.getpelican.com/"&gt;Pelican&lt;/a&gt;.  It too uses RST files to generate the site, but supports metadata in the RST files to signify things such as time of post.  It was incredibly easy to port my Tinkerer posts over so I gave it a try.&lt;/p&gt;
&lt;p&gt;I have ended up with generation scripts, RST files and a theme I have modified in a &lt;a class="reference external" href="https://github.com/LinuxJedi/linuxjedi.co.uk"&gt;GitHub repo&lt;/a&gt; and the generated content in my &lt;a class="reference external" href="https://github.com/LinuxJedi/linuxjedi.github.io"&gt;GitHub Pages Repo&lt;/a&gt;.  Pelican has a built-in HTTP server which makes it easy to preview your generated HTML before it is uploaded to the site.&lt;/p&gt;
&lt;p&gt;In conclusion, Tinkerer is a great platform, but Pelican feels more mature and it seems to have a wider community around it.  I also found its templates much easier to edit.  Both platforms have an Open Source feel to the way you create and publish content which is fantastic for my usage.  I think I have finally found a blogging platform I can settle with.&lt;/p&gt;
</summary><category term="Blog"></category><category term="LinuxJedi"></category></entry><entry><title>New Blog!</title><link href="http://linuxjedi.co.uk/posts/2014/Sep/23/new-blog/" rel="alternate"></link><updated>2014-09-23T16:45:00+01:00</updated><author><name></name></author><id>tag:linuxjedi.co.uk,2014-09-23:posts/2014/Sep/23/new-blog/</id><summary type="html">&lt;p&gt;Blogger is a great blogging platform.  Unfortunately it is really difficut to create content that has marked-up code in it.  Which as a developer is a requirement.  Therefore LinuxJedi's /dev/null has now moved to this GitHub pages site using &lt;a class="reference external" href="http://tinkerer.me/"&gt;Tinkerer&lt;/a&gt; to build it.&lt;/p&gt;
&lt;p&gt;The old site and content can still be accessed at &lt;a class="reference external" href="http://thelinuxjedi.blogspot.com/"&gt;http://thelinuxjedi.blogspot.com/&lt;/a&gt;.&lt;/p&gt;
</summary><category term="LinuxJedi"></category></entry></feed>